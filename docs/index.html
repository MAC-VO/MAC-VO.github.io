<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" href="/images/Poster.jpg"/><link rel="preload" as="image" href="/images/BastiAndPayload.jpg"/><link rel="preload" as="image" href="/images/Presentation.jpg"/><link rel="preload" as="image" href="/images/MACVODemo.jpg"/><link rel="preload" as="image" href="/images/Methods.png"/><link rel="preload" as="image" href="/images/SpatialCovariance.png"/><link rel="stylesheet" href="/_next/static/css/9f67c44f2da933ca.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/f87fff2ab93d05a7.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-39307ce8540e3650.js"/><script src="/_next/static/chunks/e904932e-45a35ed43cec0463.js" async=""></script><script src="/_next/static/chunks/538-a2946d422aaf15bf.js" async=""></script><script src="/_next/static/chunks/main-app-540929cc8518be19.js" async=""></script><script src="/_next/static/chunks/809ce7c2-c6b72ceb3175f9c8.js" async=""></script><script src="/_next/static/chunks/845-0388f8331c4fe591.js" async=""></script><script src="/_next/static/chunks/394-6160b5491686e443.js" async=""></script><script src="/_next/static/chunks/app/page-8851e9fc8924b115.js" async=""></script><script src="/_next/static/chunks/ce84277d-c3f00ebc806278a6.js" async=""></script><script src="/_next/static/chunks/app/error-4ba240e7ed3a30e8.js" async=""></script><title>MAC-VO: Metric-Aware Covariance for Learning-based Stereo Visual Odometry</title><link rel="manifest" href="/favicon/site.webmanifest" crossorigin="use-credentials"/><meta name="robots" content="index, follow"/><meta property="og:title" content="MAC-VO: Metric-Aware Covariance for Learning-based Stereo Visual Odometry"/><meta property="og:url" content="https://mac-vo.github.io"/><meta property="og:site_name" content="MAC-VO: Metric-Aware Covariance for Learning-based Stereo Visual Odometry"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://mac-vo.github.io/images/og.jpg"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="MAC-VO: Metric-Aware Covariance for Learning-based Stereo Visual Odometry"/><meta name="twitter:image" content="https://mac-vo.github.io/images/og.jpg"/><link rel="shortcut icon" href="/favicon/favicon-16x16.png"/><link rel="icon" href="/favicon/favicon.ico"/><link rel="apple-touch-icon" href="/favicon/apple-touch-icon.png"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body><main><section class="bg-white text-gray-700 relative flex items-center justify-center h-screen overflow-hidden"><div class="absolute top-6 right-4 z-20"><span>Light Mode </span><button class="group inline-flex  items-center rounded-full bg-gray-600 transition data-[checked]:bg-primary-500 h-6 w-11" id="headlessui-switch-:Rhafja:" role="switch" type="button" tabindex="0" aria-checked="true" data-headlessui-state="checked" data-checked=""><span class="size-4 group-data-[checked]:translate-x-6 translate-x-1 rounded-full bg-white transition"></span></button></div><div class="layout z-20 relative flex min-h-screen flex-col items-center justify-center p-4 text-center"><h1 class="mt-4 text-5xl">MAC-VO: <!-- --> <span class="text-primary-600">M</span>etrics-<span class="text-primary-600">A</span>ware <!-- --> <span class="text-primary-600">C</span>ovariance <!-- --> <!-- -->for Learning-based Stereo<!-- --> <span class="text-primary-600">V</span>isual <!-- --> <span class="text-primary-600">O</span>dometry</h1><div class="text-red-700 container text-xl my-4 font-bold">ICRA 2025 Best Conference Paper Award <br/>ICRA 2025 Best Paper Award on Robot Perception</div><div class="container pb-6"><span class="text-lg"><a target="_blank" rel="noopener noreferrer" href="https://haleqiu.github.io/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">Yuheng Qiu</a><span class="align-super text-sm leading-none">*1</span>,  <a target="_blank" rel="noopener noreferrer" href="https://www.yutianchen.blog/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">Yutian Chen</a><span class="align-super text-sm leading-none">*1</span>,   Zihao Zhang<span class="align-super text-sm leading-none">2</span>,  <a target="_blank" rel="noopener noreferrer" href="http://www.wangwenshan.com/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">Wenshan Wang</a><span class="align-super text-sm leading-none">1</span>,  <a target="_blank" rel="noopener noreferrer" href="https://www.ri.cmu.edu/ri-faculty/sebastian-scherer/" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">Sebastian Scherer</a><span class="align-super text-sm leading-none">1</span></span></div><div class="container flex flex-row items-center space-x-8 justify-center text-lg"><a target="_blank" rel="noopener noreferrer" href="https://github.com/MAC-VO/MAC-VO" variant="light" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 group gap-[0.25em] mt-6"><span>GitHub Repo</span><svg viewBox="0 0 16 16" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" class="relative transition-transform duration-200 motion-safe:-translate-x-1 group-hover:translate-x-0"><path fill="currentColor" d="M7.28033 3.21967C6.98744 2.92678 6.51256 2.92678 6.21967 3.21967C5.92678 3.51256 5.92678 3.98744 6.21967 4.28033L7.28033 3.21967ZM11 8L11.5303 8.53033C11.8232 8.23744 11.8232 7.76256 11.5303 7.46967L11 8ZM6.21967 11.7197C5.92678 12.0126 5.92678 12.4874 6.21967 12.7803C6.51256 13.0732 6.98744 13.0732 7.28033 12.7803L6.21967 11.7197ZM6.21967 4.28033L10.4697 8.53033L11.5303 7.46967L7.28033 3.21967L6.21967 4.28033ZM10.4697 7.46967L6.21967 11.7197L7.28033 12.7803L11.5303 8.53033L10.4697 7.46967Z"></path><path stroke="currentColor" d="M1.75 8H11" stroke-width="1.5" stroke-linecap="round" class="origin-left transition-all duration-200 opacity-0 motion-safe:-translate-x-1 group-hover:translate-x-0 group-hover:opacity-100"></path></svg></a><a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2409.09479" variant="light" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 group gap-[0.25em] mt-6"><span>arXiv Page</span><svg viewBox="0 0 16 16" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" class="relative transition-transform duration-200 motion-safe:-translate-x-1 group-hover:translate-x-0"><path fill="currentColor" d="M7.28033 3.21967C6.98744 2.92678 6.51256 2.92678 6.21967 3.21967C5.92678 3.51256 5.92678 3.98744 6.21967 4.28033L7.28033 3.21967ZM11 8L11.5303 8.53033C11.8232 8.23744 11.8232 7.76256 11.5303 7.46967L11 8ZM6.21967 11.7197C5.92678 12.0126 5.92678 12.4874 6.21967 12.7803C6.51256 13.0732 6.98744 13.0732 7.28033 12.7803L6.21967 11.7197ZM6.21967 4.28033L10.4697 8.53033L11.5303 7.46967L7.28033 3.21967L6.21967 4.28033ZM10.4697 7.46967L6.21967 11.7197L7.28033 12.7803L11.5303 8.53033L10.4697 7.46967Z"></path><path stroke="currentColor" d="M1.75 8H11" stroke-width="1.5" stroke-linecap="round" class="origin-left transition-all duration-200 opacity-0 motion-safe:-translate-x-1 group-hover:translate-x-0 group-hover:opacity-100"></path></svg></a><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=O_HowJk-GDw" variant="light" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 group gap-[0.25em] mt-6"><span>Explain Video</span><svg viewBox="0 0 16 16" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" class="relative transition-transform duration-200 motion-safe:-translate-x-1 group-hover:translate-x-0"><path fill="currentColor" d="M7.28033 3.21967C6.98744 2.92678 6.51256 2.92678 6.21967 3.21967C5.92678 3.51256 5.92678 3.98744 6.21967 4.28033L7.28033 3.21967ZM11 8L11.5303 8.53033C11.8232 8.23744 11.8232 7.76256 11.5303 7.46967L11 8ZM6.21967 11.7197C5.92678 12.0126 5.92678 12.4874 6.21967 12.7803C6.51256 13.0732 6.98744 13.0732 7.28033 12.7803L6.21967 11.7197ZM6.21967 4.28033L10.4697 8.53033L11.5303 7.46967L7.28033 3.21967L6.21967 4.28033ZM10.4697 7.46967L6.21967 11.7197L7.28033 12.7803L11.5303 8.53033L10.4697 7.46967Z"></path><path stroke="currentColor" d="M1.75 8H11" stroke-width="1.5" stroke-linecap="round" class="origin-left transition-all duration-200 opacity-0 motion-safe:-translate-x-1 group-hover:translate-x-0 group-hover:opacity-100"></path></svg></a><a target="_blank" rel="noopener noreferrer" href="https://mac-vo.github.io/wiki/" variant="light" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0 group gap-[0.25em] mt-6"><span>Documentation</span><svg viewBox="0 0 16 16" height="1em" width="1em" fill="none" xmlns="http://www.w3.org/2000/svg" class="relative transition-transform duration-200 motion-safe:-translate-x-1 group-hover:translate-x-0"><path fill="currentColor" d="M7.28033 3.21967C6.98744 2.92678 6.51256 2.92678 6.21967 3.21967C5.92678 3.51256 5.92678 3.98744 6.21967 4.28033L7.28033 3.21967ZM11 8L11.5303 8.53033C11.8232 8.23744 11.8232 7.76256 11.5303 7.46967L11 8ZM6.21967 11.7197C5.92678 12.0126 5.92678 12.4874 6.21967 12.7803C6.51256 13.0732 6.98744 13.0732 7.28033 12.7803L6.21967 11.7197ZM6.21967 4.28033L10.4697 8.53033L11.5303 7.46967L7.28033 3.21967L6.21967 4.28033ZM10.4697 7.46967L6.21967 11.7197L7.28033 12.7803L11.5303 8.53033L10.4697 7.46967Z"></path><path stroke="currentColor" d="M1.75 8H11" stroke-width="1.5" stroke-linecap="round" class="origin-left transition-all duration-200 opacity-0 motion-safe:-translate-x-1 group-hover:translate-x-0 group-hover:opacity-100"></path></svg></a></div></div><div class="absolute w-auto min-w-full min-h-full max-w-none z-10 bg-white/80"></div><div class="absolute bottom-4 left-4 z-20"><p><span class="align-super text-sm">*</span>Equal Contribution</p><p><span class="align-super text-sm">1</span>Carnegie Mellon University</p><p><span class="align-super text-sm">2</span>Shanghai Jiao Tong University</p></div><video autoPlay="" loop="" muted="" class="absolute w-auto min-w-full min-h-full max-w-none z-0"><source src="/video/MACVO_Background.mp4" type="video/mp4"/>Your browser does not support the video tag.</video></section><section class="bg-white text-gray-700"><div class="layout py-12"><h2 class="text-center pb-4">Abstract</h2><p class="text-pretty">We propose MAC-VO, a novel learning-based stereo VO that leverages the learned metrics-aware matching uncertainty for dual purposes: selecting keypoint and weighing the residual in pose graph optimization. Compared to traditional geometric methods prioritizing texture-affluent features like edges, our keypoint selector employs the learned uncertainty to filter out the low-quality features based on global inconsistency. In contrast to the learning-based algorithms that rely on the scale-agnostic weight matrix, we design a metrics-aware spatial covariance model to capture the spatial information during keypoint registration. Integrating this covariance model into pose graph optimization enhances the robustness and reliability of pose estimation, particularly in challenging environments with varying illumination, feature density, and motion patterns. On public benchmark datasets, MAC-VO outperforms existing VO algorithms, even some SLAM algorithms in challenging environments. The covariance-aware framework also provides valuable information about the reliability of the estimated poses, which can benefit decision-making for autonomous systems.</p></div></section><section class="bg-gray-100 text-gray-700"><div class="layout pt-4 pb-4"><h3 class="mt-12 mb-4">MAC-VO at ICRA 2025</h3></div><div class="wide-layout grid grid-cols-1 lg:grid-cols-12 gap-2 items-stretch pb-12"><div class="rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 lg:col-span-6 col-span-1"><p class="p-2 lg:text-lg rounded-t-xl ">ICRA Registration Lobby</p><div class="flex-grow"></div><video controls="" autoPlay="" loop="" muted="" class="rounded-xl mx-auto"><source type="video/mp4" src="/video/ICRA2025_Registration_Lobby.mp4"/></video><div class="flex-grow"></div></div><div class="rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 lg:col-span-6 col-span-1"><p class="p-2 lg:text-lg rounded-t-xl ">Main Floor <span class="p-1 rounded-lg bg-primary-900 font-light text-primary-500">Dynamic Scene</span></p><div class="flex-grow"></div><video controls="" autoPlay="" loop="" muted="" class="rounded-xl mx-auto"><source type="video/mp4" src="/video/ICRA2025_Main_Level.mp4"/></video><div class="flex-grow"></div></div><div class="rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 lg:col-span-5 col-span-1"><p class="p-2 lg:text-lg rounded-t-xl ">Presentation Room</p><div class="flex-grow"></div><video controls="" autoPlay="" loop="" muted="" class="rounded-xl mx-auto"><source type="video/mp4" src="/video/ICRA2025_Poster_Session.mp4"/></video><div class="flex-grow"></div></div><div class="rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 lg:col-span-4 col-span-1"><div class="flex-grow"></div><video controls="" autoPlay="" loop="" muted="" class="rounded-xl mx-auto"><source type="video/mp4" src="/video/ICRA2025_Poster.mp4"/></video><div class="flex-grow"></div></div><div class="rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 lg:col-span-3 col-span-1"><div class="flex-grow"></div><img class="rounded-xl mx-auto" src="/images/Poster.jpg"/><div class="flex-grow"></div></div><div class="bg-gray-100 rounded-xl flex flex-col flex-nowrap text-white col-span-1"></div><div class="rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 lg:col-span-2 col-span-1"><div class="flex-grow"></div><img class="rounded-xl mx-auto" src="/images/BastiAndPayload.jpg"/><div class="flex-grow"></div></div><div class="rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 lg:col-span-4 col-span-1"><div class="flex-grow"></div><img class="rounded-xl mx-auto" src="/images/Presentation.jpg"/><div class="flex-grow"></div></div><div class="rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 lg:col-span-4 col-span-1"><div class="flex-grow"></div><img class="rounded-xl mx-auto" src="/images/MACVODemo.jpg"/><div class="flex-grow"></div></div><div class="bg-gray-100 rounded-xl flex flex-col flex-nowrap text-white col-span-1"></div></div><section class="bg-gray-100 text-gray-700"><div class="layout pt-4 pb-4"><h3 class="mt-12 mb-4">MAC-VO Dense Mapping</h3><p class="py-4 text-lg">By incorporating our uncertainty estimates, we can reliably select feature points for dense mapping <span class="mt-2 font-bold text-primary-600">without bundle adjustment / multi-frame optimization</span>. The video below shows the dense mapping result on EuRoC, <a target="_blank" rel="noopener noreferrer" href="https://rvp-group.net/slam-dataset.html" class="cursor-newtab animated-underline custom-link inline-flex items-center font-medium focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2 border-dark border-b border-dotted hover:border-black/0">VBR</a>, TartanAir, and TartanAir v2. <span class="mt-2 font-bold text-primary-600">No post-processing is applied.</span></p><div class="flex space-x-2 mt-12"><button class="text-xl px-4 py-1 rounded-lg transition shadow-md bg-primary-600 text-white">Zed</button><button class="text-xl px-4 py-1 rounded-lg transition shadow-md bg-white text-gray-700">VBR</button><button class="text-xl px-4 py-1 rounded-lg transition shadow-md bg-white text-gray-700">TartanAir v2</button><button class="text-xl px-4 py-1 rounded-lg transition shadow-md bg-white text-gray-700">TartanAir</button><button class="text-xl px-4 py-1 rounded-lg transition shadow-md bg-white text-gray-700">EuRoC</button></div></div><div class="wide-layout grid grid-cols-1 lg:grid-cols-12 gap-2 items-stretch pb-12"><div class="rounded-xl flex flex-col text-white bg-neutral-900 col-span-6"><p class="p-2 lg:text-lg rounded-t-xl">Zed X Fire Academy 2<!-- --> </p><div class="flex-grow"></div><video controls="" loop="" muted="" autoPlay="" preload="lazy" class="rounded-xl mx-auto"><source src="/video/Zed_FireAcademy2.mp4" type="video/mp4"/></video><div class="flex-grow"></div></div><div class="rounded-xl flex flex-col text-white bg-neutral-900 col-span-6"><p class="p-2 lg:text-lg rounded-t-xl">Zed X Fire Academy 1<!-- --> </p><div class="flex-grow"></div><video controls="" loop="" muted="" autoPlay="" preload="lazy" class="rounded-xl mx-auto"><source src="/video/Zed_FireAcademy.mp4" type="video/mp4"/></video><div class="flex-grow"></div></div><div class="rounded-xl flex flex-col text-white bg-neutral-900 col-span-5"><p class="p-2 lg:text-lg rounded-t-xl">AirLab Office<!-- --> </p><div class="flex-grow"></div><video controls="" loop="" muted="" autoPlay="" preload="lazy" class="rounded-xl mx-auto"><source src="/video/AirLab_Scan.webm" type="video/webm"/></video><div class="flex-grow"></div></div><div class="rounded-xl flex flex-col text-white bg-neutral-900 col-span-7"><p class="p-2 lg:text-lg rounded-t-xl">AirLab Workbench<!-- --> </p><div class="flex-grow"></div><video controls="" loop="" muted="" autoPlay="" preload="lazy" class="rounded-xl mx-auto"><source src="/video/AirLab_Workbench.webm" type="video/webm"/></video><div class="flex-grow"></div></div></div></section></section><section class="bg-white text-gray-700"><div class="layout py-12"><h2 class="pb-4">Methods</h2><h3 class="pt-4">System Pipeline</h3><figure class="flex flex-col items-center justify-center"><img src="/images/Methods.png" class="w-full h-auto rounded-md p-2 transition invert-0"/><figcaption class="text-gray-600 mt-2 font-light">Figure <!-- -->1<!-- -->. <!-- -->MAC-VO System pipeline. First, we use a shared matching network to estimate the depth, flow, and corresponding uncertainty. Secondly, we employ the learned uncertainty to filter out unreliable features. Lastly, we optimize the pose with the metrics-aware covariance model.</figcaption></figure><h3 class="pt-4">Metrics-Aware Spatial Covariance</h3><figure class="flex flex-col items-center justify-center"><img src="/images/SpatialCovariance.png" class="w-full h-auto rounded-md p-2 transition invert-0"/><figcaption class="text-gray-600 mt-2 font-light">Figure <!-- -->2<!-- -->. <span>a) Depth uncertainty estimated with the presence of matching uncertainty. b) Projecting depth and matching uncertainty on sensor plane to 3D space. c) Residual <span>$\mathcal{L}_i$</span> for pose graph optimization.</span></figcaption></figure></div></section></main><script src="/_next/static/chunks/webpack-39307ce8540e3650.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/css/9f67c44f2da933ca.css\",\"style\"]\n2:HL[\"/_next/static/css/f87fff2ab93d05a7.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"3:I[5770,[],\"\"]\n5:I[486,[],\"ClientPageRoot\"]\n6:I[2108,[\"478\",\"static/chunks/809ce7c2-c6b72ceb3175f9c8.js\",\"845\",\"static/chunks/845-0388f8331c4fe591.js\",\"394\",\"static/chunks/394-6160b5491686e443.js\",\"931\",\"static/chunks/app/page-8851e9fc8924b115.js\"],\"default\"]\n7:I[7071,[],\"\"]\n8:I[600,[\"648\",\"static/chunks/ce84277d-c3f00ebc806278a6.js\",\"845\",\"static/chunks/845-0388f8331c4fe591.js\",\"601\",\"static/chunks/app/error-4ba240e7ed3a30e8.js\"],\"default\"]\n9:I[4008,[],\"\"]\nb:I[7936,[],\"\"]\nc:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/9f67c44f2da933ca.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L3\",null,{\"buildId\":\"S0-6GgkwwTUJbn6ANZFGk\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/\",\"initialTree\":[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"__PAGE__\",{},[[\"$L4\",[\"$\",\"$L5\",null,{\"props\":{\"params\":{},\"searchParams\":{}},\"Component\":\"$6\"}]],null],null]},[[\"$\",\"html\",null,{\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$8\",\"errorStyles\":[],\"errorScripts\":[],\"template\":[\"$\",\"$L9\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[\"$\",\"main\",null,{\"children\":[\"$\",\"section\",null,{\"className\":\"bg-white\",\"children\":[\"$\",\"div\",null,{\"className\":\"layout flex min-h-screen flex-col items-center justify-center text-center text-black\",\"children\":[[\"$\",\"svg\",null,{\"stroke\":\"currentColor\",\"fill\":\"currentColor\",\"strokeWidth\":\"0\",\"viewBox\":\"0 0 24 24\",\"className\":\"drop-shadow-glow animate-flicker text-red-500\",\"children\":[\"$undefined\",[[\"$\",\"path\",\"0\",{\"d\":\"M4.00098 20V14C4.00098 9.58172 7.5827 6 12.001 6C16.4193 6 20.001 9.58172 20.001 14V20H21.001V22H3.00098V20H4.00098ZM6.00098 14H8.00098C8.00098 11.7909 9.79184 10 12.001 10V8C8.68727 8 6.00098 10.6863 6.00098 14ZM11.001 2H13.001V5H11.001V2ZM19.7792 4.80761L21.1934 6.22183L19.0721 8.34315L17.6578 6.92893L19.7792 4.80761ZM2.80859 6.22183L4.22281 4.80761L6.34413 6.92893L4.92991 8.34315L2.80859 6.22183Z\",\"children\":\"$undefined\"}]]],\"style\":{\"color\":\"$undefined\"},\"height\":60,\"width\":60,\"xmlns\":\"http://www.w3.org/2000/svg\"}],[\"$\",\"h1\",null,{\"className\":\"mt-8 text-4xl md:text-6xl\",\"children\":\"Page Not Found\"}],[\"$\",\"a\",null,{\"href\":\"/\",\"children\":\"Back to home\"}]]}]}]}],\"notFoundStyles\":[],\"styles\":[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/f87fff2ab93d05a7.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[false,\"$La\"],\"globalErrorComponent\":\"$b\",\"missingSlots\":\"$Wc\"}]]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"MAC-VO: Metric-Aware Covariance for Learning-based Stereo Visual Odometry\"}],[\"$\",\"link\",\"3\",{\"rel\":\"manifest\",\"href\":\"/favicon/site.webmanifest\",\"crossOrigin\":\"use-credentials\"}],[\"$\",\"meta\",\"4\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:title\",\"content\":\"MAC-VO: Metric-Aware Covariance for Learning-based Stereo Visual Odometry\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:url\",\"content\":\"https://mac-vo.github.io\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:site_name\",\"content\":\"MAC-VO: Metric-Aware Covariance for Learning-based Stereo Visual Odometry\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image\",\"content\":\"https://mac-vo.github.io/images/og.jpg\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"MAC-VO: Metric-Aware Covariance for Learning-based Stereo Visual Odometry\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:image\",\"content\":\"https://mac-vo.github.io/images/og.jpg\"}],[\"$\",\"link\",\"14\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon/favicon-16x16.png\"}],[\"$\",\"link\",\"15\",{\"rel\":\"icon\",\"href\":\"/favicon/favicon.ico\"}],[\"$\",\"link\",\"16\",{\"rel\":\"apple-touch-icon\",\"href\":\"/favicon/apple-touch-icon.png\"}]]\n4:null\n"])</script></body></html>