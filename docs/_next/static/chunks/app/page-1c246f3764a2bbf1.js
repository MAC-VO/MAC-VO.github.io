(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[931],{5223:function(e,s,a){Promise.resolve().then(a.bind(a,2108))},2108:function(e,s,a){"use strict";a.r(s),a.d(s,{default:function(){return b}});var t=a(9390),r=a(7281),n=a(7155),i=a.n(n),l=a(4243),o=a(9132),c=a(965);o.z.object({NEXT_PUBLIC_SHOW_LOGGER:o.z.enum(["true","false"]).optional()}).parse(c.env);var d=function(){let[e,s]=(0,l.useState)("light");return(0,l.useEffect)(()=>{var e;let a=(e="darkMode",window.localStorage.getItem(e));null===a?s("dark"):s(a)},[]),(0,l.useEffect)(()=>{var s;s="darkMode",window.localStorage.setItem(s,e)},[e]),[e,()=>{s(e=>"light"===e?"dark":"light")}]},m=a(2684),x=function(e){let{state:s,switch_state:a,size:n="normal"}=e;return(0,t.jsx)(m.rs,{checked:s,onChange:a,className:(0,r.Z)("group inline-flex  items-center rounded-full bg-gray-600 transition data-[checked]:bg-primary-500","normal"===n?"h-6 w-11":"h-4 w-9"),children:(0,t.jsx)("span",{className:(0,r.Z)("normal"===n?"size-4 group-data-[checked]:translate-x-6":"size-3 group-data-[checked]:translate-x-5","translate-x-1 rounded-full bg-white transition")})})},p=e=>{let{img_src:s,caption:a,isDark:n,idx:i}=e,o=n?"text-gray-400":"text-gray-600",[c,d]=(0,l.useState)(n?"invert":"invert-0");return(0,l.useEffect)(()=>{d(n?"invert":"invert-0")},[n]),(0,t.jsxs)("figure",{className:"flex flex-col items-center justify-center",children:[(0,t.jsx)("img",{src:s,className:(0,r.Z)("w-full h-auto rounded-md p-2 transition",c,"invert"===c?"bg-gray-200":"")}),n?(0,t.jsxs)("div",{className:(0,r.Z)(o,"text-sm","invert"===c?"text-primary-500":""),children:[(0,t.jsxs)("span",{children:["Color Inversion ","invert"===c?"ON":"OFF"," "]}),(0,t.jsx)(x,{state:"invert"===c,switch_state:()=>d("invert"===c?"invert-0":"invert"),size:"small"})]}):null,(0,t.jsxs)("figcaption",{className:(0,r.Z)(o,"mt-2","font-light"),children:["Figure ",i,". ",a]})]})},h=a(7894),u=a.n(h);function g(e){let{text:s,...a}=e,r=(0,l.useRef)();return(0,l.useEffect)(()=>{r.current&&u()(r.current,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})},[s]),(0,t.jsx)("span",{ref:r,...a,children:s})}a(7297);var f=a(7112),v=a(4414);let j=l.forwardRef((e,s)=>{let{children:a,href:r,openNewTab:n,className:i,nextLinkProps:l,...o}=e;return(void 0!==n?n:r&&!r.startsWith("/")&&!r.startsWith("#"))?(0,t.jsx)("a",{ref:s,target:"_blank",rel:"noopener noreferrer",href:r,...o,className:(0,f.cn)("cursor-newtab",i),children:a}):(0,t.jsx)(v.default,{href:r,ref:s,className:i,...o,...l,children:a})}),N=l.forwardRef((e,s)=>{let{children:a,className:r,...n}=e;return(0,t.jsx)(j,{ref:s,...n,className:(0,f.cn)("animated-underline custom-link inline-flex items-center font-medium","focus-visible:ring-primary-500 focus:outline-none focus-visible:rounded focus-visible:ring focus-visible:ring-offset-2","border-dark border-b border-dotted hover:border-black/0",r),children:a})});function w(e){let{children:s,className:a,direction:r="right",as:n,icon:i=null,...l}=e,o=n||N;return(0,t.jsxs)(o,{...l,className:(0,f.cn)("group gap-[0.25em]","left"===r&&"flex-row-reverse",a),children:[i,(0,t.jsx)("span",{children:s}),(0,t.jsxs)("svg",{viewBox:"0 0 16 16",height:"1em",width:"1em",fill:"none",xmlns:"http://www.w3.org/2000/svg",className:(0,f.cn)("relative","transition-transform duration-200","right"===r?"motion-safe:-translate-x-1":"rotate-180","group-hover:translate-x-0"),children:[(0,t.jsx)("path",{fill:"currentColor",d:"M7.28033 3.21967C6.98744 2.92678 6.51256 2.92678 6.21967 3.21967C5.92678 3.51256 5.92678 3.98744 6.21967 4.28033L7.28033 3.21967ZM11 8L11.5303 8.53033C11.8232 8.23744 11.8232 7.76256 11.5303 7.46967L11 8ZM6.21967 11.7197C5.92678 12.0126 5.92678 12.4874 6.21967 12.7803C6.51256 13.0732 6.98744 13.0732 7.28033 12.7803L6.21967 11.7197ZM6.21967 4.28033L10.4697 8.53033L11.5303 7.46967L7.28033 3.21967L6.21967 4.28033ZM10.4697 7.46967L6.21967 11.7197L7.28033 12.7803L11.5303 8.53033L10.4697 7.46967Z"}),(0,t.jsx)("path",{stroke:"currentColor",d:"M1.75 8H11",strokeWidth:"1.5",strokeLinecap:"round",className:(0,f.cn)("origin-left transition-all duration-200","opacity-0 motion-safe:-translate-x-1","group-hover:translate-x-0 group-hover:opacity-100")})]})]})}function b(){let[e,s]=d(),a="dark"===e?"text-gray-300":"text-gray-700",n="dark"===e?"bg-dark":"bg-white",o="dark"===e?"bg-dark/80":"bg-white/80",c="dark"===e?"bg-neutral-700":"bg-gray-100",m="dark"===e?"text-primary-500":"text-primary-600",h="dark"===e?"text-red-600":"text-red-700",u="dark"===e?"bg-primary-500":"bg-primary-600",f={Zed:[{title:"Zed X Fire Academy 2",src:"/video/Zed_FireAcademy2.mp4",className:"col-span-6"},{title:"Zed X Fire Academy 1",src:"/video/Zed_FireAcademy.mp4",className:"col-span-6"},{title:"AirLab Office",src:"/video/AirLab_Scan.webm",className:"col-span-5"},{title:"AirLab Workbench",src:"/video/AirLab_Workbench.webm",className:"col-span-7"}],VBR:[{title:"VBR Diag Train 0",src:"/video/VBR_Diag_Train0.mp4",className:"col-span-7"},{title:"VBR Spagna Test 0",src:"/video/VBR_Spagna_Test0.mp4",badge:"Dynamic Scene",className:"col-span-5"},{title:"VBR Spagna Test 0 (2)",src:"/video/VBR_Spagna_Test0_2.mp4",badge:"Dynamic Scene",className:"col-span-5"},{title:"VBR Colosseo Train 0",src:"/video/VBR_Colosseo_Train0.mp4",badge:"Extreme Exposure",className:"col-span-7"}],"TartanAir v2":[{title:"TartanAir v2 – Abandon School 1",src:"/video/TartanAirv2_AbandonedSchoolP001.mp4",className:"col-span-5"},{title:"TartanAir v2 Test (Easy) 3",src:"/video/TartanAirv2_Test_E003.mp4",className:"col-span-7"}],TartanAir:[{title:"TartanAir – Abandon Factory 1",src:"/video/TartanAir_AbandonedFactory_P001.mp4",className:"col-span-5"},{title:"TartanAir – House 1",src:"/video/TartanAir_HouseP001.mp4",className:"col-span-7"}],EuRoC:[{title:"EuRoC V102",src:"/video/EuRoC_V102.mp4",className:"col-span-7"}]},v=Object.keys(f),[j,b]=(0,l.useState)(v[0]);return(0,t.jsxs)("main",{children:[(0,t.jsx)(i(),{children:(0,t.jsx)("meta",{name:"google-site-verification",content:"wORtJ7fq4X_rDll9Ym7DJ4lHQvSwbb87d_dflv28rN8"})}),(0,t.jsxs)("section",{className:(0,r.Z)(n,a,"relative flex items-center justify-center h-screen overflow-hidden"),children:[(0,t.jsxs)("div",{className:"absolute top-6 right-4 z-20",children:[(0,t.jsx)("span",{children:"Light Mode "}),(0,t.jsx)(x,{state:"light"===e,switch_state:s})]}),(0,t.jsxs)("div",{className:"layout z-20 relative flex min-h-screen flex-col items-center justify-center p-4 text-center",children:[(0,t.jsxs)("h1",{className:"mt-4 text-5xl",children:["MAC-VO: "," ",(0,t.jsx)("span",{className:m,children:"M"}),"etrics-",(0,t.jsx)("span",{className:m,children:"A"}),"ware "," ",(0,t.jsx)("span",{className:m,children:"C"}),"ovariance "," ","for Learning-based Stereo"," ",(0,t.jsx)("span",{className:m,children:"V"}),"isual "," ",(0,t.jsx)("span",{className:m,children:"O"}),"dometry"]}),(0,t.jsxs)("div",{className:(0,r.Z)(h,"container text-xl my-4 font-bold"),children:["ICRA 2025 Best Conference Paper Award ",(0,t.jsx)("br",{}),"ICRA 2025 Best Paper Award on Robot Perception"]}),(0,t.jsx)("div",{className:"container pb-6",children:(0,t.jsxs)("span",{className:"text-lg",children:[(0,t.jsx)(N,{href:"https://haleqiu.github.io/",children:"Yuheng Qiu"}),(0,t.jsx)("span",{className:"align-super text-sm leading-none",children:"*1"}),", \xa0",(0,t.jsx)(N,{href:"https://www.yutianchen.blog/",children:"Yutian Chen"}),(0,t.jsx)("span",{className:"align-super text-sm leading-none",children:"*1"}),", \xa0 Zihao Zhang",(0,t.jsx)("span",{className:"align-super text-sm leading-none",children:"2"}),", \xa0",(0,t.jsx)(N,{href:"http://www.wangwenshan.com/",children:"Wenshan Wang"}),(0,t.jsx)("span",{className:"align-super text-sm leading-none",children:"1"}),", \xa0",(0,t.jsx)(N,{href:"https://www.ri.cmu.edu/ri-faculty/sebastian-scherer/",children:"Sebastian Scherer"}),(0,t.jsx)("span",{className:"align-super text-sm leading-none",children:"1"})]})}),(0,t.jsxs)("div",{className:"container flex flex-row items-center space-x-8 justify-center text-lg",children:[(0,t.jsx)(w,{className:"mt-6",href:"https://github.com/MAC-VO/MAC-VO",variant:e,size:"large",children:"GitHub Repo"}),(0,t.jsx)(w,{className:"mt-6",href:"https://arxiv.org/abs/2409.09479",variant:e,size:"large",children:"arXiv Page"}),(0,t.jsx)(w,{className:"mt-6",href:"https://www.youtube.com/watch?v=O_HowJk-GDw",variant:e,size:"large",children:"Explain Video"}),(0,t.jsx)(w,{className:"mt-6",href:"https://mac-vo.github.io/wiki/",variant:e,size:"large",children:"Documentation"})]})]}),(0,t.jsx)("div",{className:(0,r.Z)("absolute w-auto min-w-full min-h-full max-w-none z-10",o)}),(0,t.jsxs)("div",{className:"absolute bottom-4 left-4 z-20",children:[(0,t.jsxs)("p",{children:[(0,t.jsx)("span",{className:"align-super text-sm",children:"*"}),"Equal Contribution"]}),(0,t.jsxs)("p",{children:[(0,t.jsx)("span",{className:"align-super text-sm",children:"1"}),"Carnegie Mellon University"]}),(0,t.jsxs)("p",{children:[(0,t.jsx)("span",{className:"align-super text-sm",children:"2"}),"Shanghai Jiao Tong University"]})]}),(0,t.jsxs)("video",{autoPlay:!0,loop:!0,muted:!0,className:"absolute w-auto min-w-full min-h-full max-w-none z-0",children:[(0,t.jsx)("source",{src:"/video/MACVO_Background.mp4",type:"video/mp4"}),"Your browser does not support the video tag."]})]}),(0,t.jsx)("section",{className:(0,r.Z)(n,a),children:(0,t.jsxs)("div",{className:"layout py-12",children:[(0,t.jsx)("h2",{className:"text-center pb-4",children:"Abstract"}),(0,t.jsx)("p",{className:"text-pretty",children:"We propose MAC-VO, a novel learning-based stereo VO that leverages the learned metrics-aware matching uncertainty for dual purposes: selecting keypoint and weighing the residual in pose graph optimization. Compared to traditional geometric methods prioritizing texture-affluent features like edges, our keypoint selector employs the learned uncertainty to filter out the low-quality features based on global inconsistency. In contrast to the learning-based algorithms that rely on the scale-agnostic weight matrix, we design a metrics-aware spatial covariance model to capture the spatial information during keypoint registration. Integrating this covariance model into pose graph optimization enhances the robustness and reliability of pose estimation, particularly in challenging environments with varying illumination, feature density, and motion patterns. On public benchmark datasets, MAC-VO outperforms existing VO algorithms, even some SLAM algorithms in challenging environments. The covariance-aware framework also provides valuable information about the reliability of the estimated poses, which can benefit decision-making for autonomous systems."})]})}),(0,t.jsxs)("section",{className:(0,r.Z)(c,a),children:[(0,t.jsx)("div",{className:"layout pt-4 pb-4",children:(0,t.jsx)("h3",{className:"mt-12 mb-4",children:"MAC-VO at ICRA 2025"})}),(0,t.jsxs)("div",{className:"wide-layout grid grid-cols-1 lg:grid-cols-12 gap-2 items-stretch pb-12",children:[(0,t.jsxs)("div",{className:"rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 col-span-6",children:[(0,t.jsx)("p",{className:"p-2 lg:text-lg rounded-t-xl ",children:"ICRA Registration Lobby"}),(0,t.jsx)("div",{className:"flex-grow"}),(0,t.jsx)("video",{controls:!0,autoPlay:!0,loop:!0,muted:!0,className:"rounded-xl mx-auto",children:(0,t.jsx)("source",{type:"video/mp4",src:"/video/ICRA2025_Registration_Lobby.mp4"})}),(0,t.jsx)("div",{className:"flex-grow"})]}),(0,t.jsxs)("div",{className:"rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 col-span-6",children:[(0,t.jsxs)("p",{className:"p-2 lg:text-lg rounded-t-xl ",children:["Main Floor ",(0,t.jsx)("span",{className:"p-1 rounded-lg bg-primary-900 font-light text-primary-500",children:"Dynamic Scene"})]}),(0,t.jsx)("div",{className:"flex-grow"}),(0,t.jsx)("video",{controls:!0,autoPlay:!0,loop:!0,muted:!0,className:"rounded-xl mx-auto",children:(0,t.jsx)("source",{type:"video/mp4",src:"/video/ICRA2025_Main_Level.mp4"})}),(0,t.jsx)("div",{className:"flex-grow"})]}),(0,t.jsxs)("div",{className:"rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 col-span-5",children:[(0,t.jsx)("p",{className:"p-2 lg:text-lg rounded-t-xl ",children:"Presentation Room"}),(0,t.jsx)("div",{className:"flex-grow"}),(0,t.jsx)("video",{controls:!0,autoPlay:!0,loop:!0,muted:!0,className:"rounded-xl mx-auto",children:(0,t.jsx)("source",{type:"video/mp4",src:"/video/ICRA2025_Poster_Session.mp4"})}),(0,t.jsx)("div",{className:"flex-grow"})]}),(0,t.jsxs)("div",{className:"rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 col-span-4",children:[(0,t.jsx)("div",{className:"flex-grow"}),(0,t.jsx)("video",{controls:!0,autoPlay:!0,loop:!0,muted:!0,className:"rounded-xl mx-auto",children:(0,t.jsx)("source",{type:"video/mp4",src:"/video/ICRA2025_Poster.mp4"})}),(0,t.jsx)("div",{className:"flex-grow"})]}),(0,t.jsxs)("div",{className:"rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 col-span-3",children:[(0,t.jsx)("div",{className:"flex-grow"}),(0,t.jsx)("img",{className:"rounded-xl mx-auto",src:"/images/Poster.jpg"}),(0,t.jsx)("div",{className:"flex-grow"})]}),(0,t.jsx)("div",{className:"rounded-xl flex flex-col flex-nowrap text-white bg-neutral-500 col-span-2"}),(0,t.jsxs)("div",{className:"rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 col-span-2",children:[(0,t.jsx)("div",{className:"flex-grow"}),(0,t.jsx)("img",{className:"rounded-xl mx-auto",src:"/images/BastiAndPayload.jpg"}),(0,t.jsx)("div",{className:"flex-grow"})]}),(0,t.jsxs)("div",{className:"rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 col-span-4",children:[(0,t.jsx)("div",{className:"flex-grow"}),(0,t.jsx)("img",{className:"rounded-xl mx-auto",src:"/images/Presentation.jpg"}),(0,t.jsx)("div",{className:"flex-grow"})]}),(0,t.jsxs)("div",{className:"rounded-xl flex flex-col flex-nowrap text-white bg-neutral-900 col-span-4",children:[(0,t.jsx)("div",{className:"flex-grow"}),(0,t.jsx)("img",{className:"rounded-xl mx-auto",src:"/images/MACVODemo.jpg"}),(0,t.jsx)("div",{className:"flex-grow"})]})]}),(0,t.jsxs)("section",{className:(0,r.Z)(c,a),children:[(0,t.jsxs)("div",{className:"layout pt-4 pb-4",children:[(0,t.jsx)("h3",{className:"mt-12 mb-4",children:"MAC-VO Dense Mapping"}),(0,t.jsxs)("p",{className:"py-4 text-lg",children:["By incorporating our uncertainty estimates, we can reliably select feature points for dense mapping ",(0,t.jsx)("span",{className:"mt-2 font-bold text-primary-600",children:"without bundle adjustment / multi-frame optimization"}),". The video below shows the dense mapping result on EuRoC, ",(0,t.jsx)(N,{href:"https://rvp-group.net/slam-dataset.html",children:"VBR"}),", TartanAir, and TartanAir v2. ",(0,t.jsx)("span",{className:"mt-2 font-bold text-primary-600",children:"No post-processing is applied."})]}),(0,t.jsx)("div",{className:"flex space-x-2 mt-12",children:v.map(e=>(0,t.jsx)("button",{onClick:()=>b(e),className:(0,r.Z)("text-xl px-4 py-1 rounded-lg transition shadow-md",j===e?(0,r.Z)(u,"text-white"):(0,r.Z)(n,a)),children:e},e))})]}),(0,t.jsx)("div",{className:"wide-layout grid grid-cols-1 lg:grid-cols-12 gap-2 items-stretch pb-12",children:f[j].map(e=>{let{title:s,src:a,badge:n,className:i}=e;return(0,t.jsxs)("div",{className:(0,r.Z)("rounded-xl flex flex-col text-white bg-neutral-900",i),children:[(0,t.jsxs)("p",{className:"p-2 lg:text-lg rounded-t-xl",children:[s," ",n&&(0,t.jsx)("span",{className:"p-1 rounded-lg bg-primary-900 font-light text-base text-primary-500",children:n})]}),(0,t.jsx)("div",{className:"flex-grow"}),(0,t.jsx)("video",{controls:!0,loop:!0,muted:!0,autoPlay:!0,preload:"lazy",className:"rounded-xl mx-auto",children:(0,t.jsx)("source",{src:a,type:"video/mp4"})}),(0,t.jsx)("div",{className:"flex-grow"})]},a)})})]})]}),(0,t.jsx)("section",{className:(0,r.Z)(n,a),children:(0,t.jsxs)("div",{className:"layout py-12",children:[(0,t.jsx)("h2",{className:"pb-4",children:"Methods"}),(0,t.jsx)("h3",{className:"pt-4",children:"System Pipeline"}),(0,t.jsx)(p,{img_src:"/images/Methods.png",caption:"MAC-VO System pipeline. First, we use a shared matching network to estimate the depth, flow, and corresponding uncertainty. Secondly, we employ the learned uncertainty to filter out unreliable features. Lastly, we optimize the pose with the metrics-aware covariance model.",isDark:"dark"===e,idx:1}),(0,t.jsx)("h3",{className:"pt-4",children:"Metrics-Aware Spatial Covariance"}),(0,t.jsx)(p,{img_src:"/images/SpatialCovariance.png",caption:(0,t.jsxs)("span",{children:["a) Depth uncertainty estimated with the presence of matching uncertainty. b) Projecting depth and matching uncertainty on sensor plane to 3D space. c) Residual ",(0,t.jsx)(g,{text:"$\\mathcal{L}_i$"})," for pose graph optimization."]}),isDark:"dark"===e,idx:2})]})})]})}},7112:function(e,s,a){"use strict";a.d(s,{cn:function(){return n}});var t=a(7281),r=a(5834);function n(){for(var e=arguments.length,s=Array(e),a=0;a<e;a++)s[a]=arguments[a];return(0,r.m6)((0,t.Z)(s))}}},function(e){e.O(0,[76,478,845,394,483,538,744],function(){return e(e.s=5223)}),_N_E=e.O()}]);